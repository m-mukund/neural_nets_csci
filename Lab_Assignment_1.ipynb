{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fg8BSVK4OcFx"
   },
   "source": [
    "# Lab Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pit0BSlkOfcw"
   },
   "source": [
    "Student name: [Mukund Mahesan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXp58l3vrC1L"
   },
   "source": [
    "## Notebook version\n",
    "\n",
    "This notebook includes all the codes in the codebase of lab assignment 1. Completing and submitting this script is equivalent to submitting the codebase. Please note that your submitted script should include errorless cell outputs that contain necessary information that proves you have successfully run the notebook in your own directory.\n",
    "\n",
    "You can choose to (1) run this notebook locally on your end or (2) run this notebook on colab. For the former, you will need to download the dataset to your device that resembles the instructions for the codebase. For the latter, **you will need to upload the dataset to your Google Drive** account, and connect your colab notebook to your Google Drive. Then, go to \"File->Save a copy in Drive\" to create a copy you can edit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWOk8c6QstJ2"
   },
   "source": [
    "#### Colab (if applicable)\n",
    "\n",
    "If you are running this script on colab, uncomment and run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OATj2nvHs2O1"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHvOW4Qxs30Y"
   },
   "source": [
    "Note that the Google Drive directory has the root `/content/drive/`. For instance, my directory to the dataset is `'/content/drive/My Drive/Courses/CSCI 5922/CSCI 5922 SP25/Demo/MNIST/'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ufLsFPnq6gu"
   },
   "source": [
    "### mnist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "nqaf3LuXOa1c"
   },
   "outputs": [],
   "source": [
    "#Original source: https://www.kaggle.com/code/hojjatk/read-mnist-dataset\n",
    "#It has been modified for ease of use w/ pytorch\n",
    "\n",
    "#You do NOT need to modify ANY code in this file!\n",
    "\n",
    "import numpy as np\n",
    "import struct\n",
    "from array import array\n",
    "import torch\n",
    "\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "\n",
    "    def read_images_labels(self, images_filepath, labels_filepath):\n",
    "        n = 60000 if \"train\" in images_filepath else 10000\n",
    "        labels = torch.zeros((n, 10))\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            l = torch.tensor(array(\"B\", file.read())).unsqueeze(-1)\n",
    "            l = torch.concatenate((torch.arange(0, n).unsqueeze(-1), l), dim = 1).type(torch.int32)\n",
    "            labels[l[:,0], l[:,1]] = 1\n",
    "\n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())\n",
    "        images = torch.zeros((n, 28**2))\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            #img = img.reshape(28, 28)\n",
    "            images[i, :] = torch.tensor(img)\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpKgf2fMquMh"
   },
   "source": [
    "### activations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "WuJUuwXrOoVg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ReLU():\n",
    "    #Complete this class\n",
    "    def forward(x: torch.tensor) -> torch.tensor:\n",
    "        #implement ReLU(x) here\n",
    "        return torch.max(torch.tensor(0, dtype=x.dtype, device=x.device), x)\n",
    "\n",
    "    def backward(delta: torch.tensor, x: torch.tensor) -> torch.tensor:\n",
    "        #implement delta * ReLU'(x) here\n",
    "        return torch.where(x > 0, delta, torch.tensor(0., dtype=x.dtype, device=x.device))\n",
    "\n",
    "class LeakyReLU():\n",
    "    #Complete this class\n",
    "    def forward(x: torch.tensor) -> torch.tensor:\n",
    "        #implement LeakyReLU(x) here\n",
    "        return torch.where(x > 0, x, x * 0.1)\n",
    "\n",
    "    def backward(delta: torch.tensor, x: torch.tensor) -> torch.tensor:\n",
    "        #implement delta * LeakyReLU'(x) here\n",
    "        return torch.where(x > 0, delta, delta * 0.1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0L2zEHN7qxuh"
   },
   "source": [
    "### framework.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "xjBDqIScO-hy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1178.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.6586)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 2045.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 19.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1303.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.2583)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 2292.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 31.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 117/117 [00:00<00:00, 984.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.9453)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 1376.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 44.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1138.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.7095)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 1983.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 53.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1299.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.5316)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 2050.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 59.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1198.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.3947)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 1591.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 64.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1164.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.2847)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 1981.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 68.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1143.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.1960)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 1478.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 71.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1218.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.1219)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 1909.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(1.9704) Test Accuracy: 73.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1231.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.0588)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 1854.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 75.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1332.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.0046)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 2087.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 76.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1339.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.9579)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 2178.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 78.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1310.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.9167)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 2024.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 79.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1342.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.8804)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 2323.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 80.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1467.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.8479)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 2223.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 80.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1405.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.8188)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 2439.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 81.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1386.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.7926)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 2254.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 82.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1424.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.7681)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 2228.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 82.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1297.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.7466)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 1781.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 82.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1189.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.7267)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 2150.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 83.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1236.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.7082)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 2296.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 83.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1266.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.6913)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 1998.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 84.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1143.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.6753)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 1894.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 84.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1162.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.6609)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 1821.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 84.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1074.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.6470)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 19/19 [00:00<00:00, 2039.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(nan) Test Accuracy: 84.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "class MLP:\n",
    "    '''\n",
    "    This class should implement a generic MLP learning framework. The core structure of the program has been provided for you.\n",
    "    But, you need to complete the following functions:\n",
    "    1: initialize()\n",
    "    2: forward(), including activations\n",
    "    3: backward(), including activations\n",
    "    4: TrainMLP()\n",
    "    '''\n",
    "    def __init__(self, layer_sizes: list[int]):\n",
    "        #Storage for model parameters\n",
    "        self.layer_sizes: list[int] = layer_sizes\n",
    "        self.num_layers = len(layer_sizes) - 1\n",
    "        self.weights: list[torch.tensor] = []\n",
    "        self.biases: list[torch.tensor] = []\n",
    "\n",
    "        #Temporary data\n",
    "        self.features: list[torch.tensor] = []\n",
    "\n",
    "        #hyper-parameters w/ default values\n",
    "        self.learning_rate: float = 1\n",
    "        self.batch_size: int = 1\n",
    "        self.activation_function: callable[[torch.tensor], torch.tensor] = ReLU\n",
    "\n",
    "    def set_hp(self, lr: float, bs: int, activation: object) -> None:\n",
    "        self.learning_rate = lr\n",
    "        self.batch_size = bs\n",
    "        self.activation_function = activation\n",
    "\n",
    "        return\n",
    "\n",
    "    def initialize(self) -> None:\n",
    "        #Complete this function\n",
    "\n",
    "        '''\n",
    "        initialize all biases to zero, and all weights with random sampling from a unifrom distribution.\n",
    "        This uniform distribution should have range +/- sqrt(6 / (d_in + d_out))\n",
    "        '''\n",
    "        for i in range(self.num_layers):  # Iterate over layers (excluding input)\n",
    "            d_in, d_out = self.layer_sizes[i], self.layer_sizes[i + 1]\n",
    "            limit = (6 / (d_in + d_out)) ** 0.5\n",
    "            W = torch.empty(d_out, d_in).uniform_(-limit, limit)\n",
    "            self.weights.append(W)\n",
    "            temp_b = torch.zeros(d_out)\n",
    "            self.biases.append(temp_b)\n",
    "\n",
    "\n",
    "        return\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        #Complete this function\n",
    "\n",
    "        '''\n",
    "        This function should loop over all layers, forward propagating the input via:\n",
    "        x_i+1 = f(x_iW + b)\n",
    "        Remember to STORE THE INTERMEDIATE FEATURES!\n",
    "        '''\n",
    "        self.features=[x]\n",
    "        z=x\n",
    "        for i in range(self.num_layers):\n",
    "            z=torch.matmul(z, self.weights[i].T) + self.biases[i]\n",
    "            if i < self.num_layers -1:\n",
    "                z=self.activation_function.forward(z)\n",
    "            self.features.append(z)\n",
    "\n",
    "        z=(torch.exp(z))\n",
    "        return z/ (torch.sum(z, dim=1, keepdim=True))\n",
    "\n",
    "    def backward(self, delta: torch.tensor) -> None:\n",
    "        #Complete this function\n",
    "\n",
    "        '''\n",
    "        This function should backpropagate the provided delta through the entire MLP, and update the weights according to the hyper-parameters\n",
    "        stored in the class variables.\n",
    "        '''\n",
    "        batch_size = delta.shape[0]\n",
    "        gradients_w = []\n",
    "        gradients_b = []\n",
    "\n",
    "        for i in reversed(range(self.num_layers)):\n",
    "            # if i < self.num_layers - 1:\n",
    "            #     delta = self.activation_function.backward(delta, self.features[i+1])\n",
    "            \n",
    "            gradients_w.insert(0, torch.matmul(delta.T, self.features[i]))\n",
    "            gradients_b.insert(0, torch.mean(delta, dim = 0))\n",
    "\n",
    "            if i > 0:\n",
    "                delta = torch.matmul(delta, self.weights[i])\n",
    "                delta = self.activation_function.backward(delta, self.features[i])\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            self.weights[i] -= self.learning_rate * gradients_w[i]\n",
    "            self.biases[i] -= self.learning_rate * gradients_b[i]\n",
    "        return\n",
    "\n",
    "\n",
    "def TrainMLP(model: MLP, x_train: torch.tensor, y_train: torch.tensor) -> MLP:\n",
    "    #Complete this function\n",
    "\n",
    "    '''\n",
    "    This function should train the MLP for 1 epoch, using the provided data and forward/backward propagating as necessary.\n",
    "    '''\n",
    "\n",
    "    #set up a random sampling of the data\n",
    "    bs = model.batch_size\n",
    "    N = x_train.shape[0]\n",
    "    rng = np.random.default_rng()\n",
    "    idx = rng.permutation(N)\n",
    "\n",
    "    #variable to accumulate total loss over the epoch\n",
    "    L = 0\n",
    "\n",
    "    for i in tqdm.tqdm(range(N // bs)):\n",
    "        x = x_train[idx[i * bs:(i + 1) * bs], ...]\n",
    "        y = y_train[idx[i * bs:(i + 1) * bs], ...]\n",
    "\n",
    "        #forward propagate and compute loss (l) here\n",
    "        prediction=model.forward(x)\n",
    "        l=-(torch.sum(y* torch.log(prediction)))\n",
    "        if not torch.isnan(l):\n",
    "            L += l\n",
    "        delta=prediction-y\n",
    "        #backpropagate here\n",
    "        model.backward(delta)\n",
    "\n",
    "    print(\"Train Loss:\", L / ((N // bs) * bs))\n",
    "    return\n",
    "\n",
    "\n",
    "def TestMLP(model: MLP, x_test: torch.tensor, y_test: torch.tensor) -> tuple[float, float]:\n",
    "    bs = model.batch_size\n",
    "    N = x_test.shape[0]\n",
    "\n",
    "    rng = np.random.default_rng()\n",
    "    idx = rng.permutation(N)\n",
    "\n",
    "    L = 0\n",
    "    A = 0\n",
    "\n",
    "    for i in tqdm.tqdm(range(N // bs)):\n",
    "        x = x_test[idx[i * bs:(i + 1) * bs], ...]\n",
    "        y = y_test[idx[i * bs:(i + 1) * bs], ...]\n",
    "\n",
    "        y_hat = model.forward(x)\n",
    "        p = torch.exp(y_hat)\n",
    "        p /= torch.sum(p, dim = 1, keepdim = True)\n",
    "        l = -1 * torch.sum(y * torch.log(p))\n",
    "        L += l\n",
    "\n",
    "        A += torch.sum(torch.where(torch.argmax(p, dim = 1) == torch.argmax(y, dim = 1), 1, 0))\n",
    "\n",
    "    print(\"Test Loss:\", L / ((N // bs) * bs), \"Test Accuracy: {:.2f}%\".format(100 * A / ((N // bs) * bs)))\n",
    "\n",
    "def normalize_mnist() -> tuple[torch.tensor, torch.tensor, torch.tensor, torch.tensor]:\n",
    "    '''\n",
    "    This function loads the MNIST dataset, then normalizes the \"X\" values to have zero mean, unit variance.\n",
    "    '''\n",
    "\n",
    "    #IMPORTANT!!!#\n",
    "    #UPDATE THE PATH BELOW!#\n",
    "    base_path = \"/Users/mukund/Documents/Neural Nets/MNIST/\"\n",
    "    #^^^^^^^^#\n",
    "\n",
    "\n",
    "    mnist = MnistDataloader(base_path + \"train-images.idx3-ubyte\", base_path + \"train-labels.idx1-ubyte\",\n",
    "                            base_path + \"t10k-images.idx3-ubyte\", base_path + \"t10k-labels.idx1-ubyte\")\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    x_mean = torch.mean(x_train, dim = 0, keepdim = True)\n",
    "    x_std = torch.std(x_train, dim = 0, keepdim = True)\n",
    "\n",
    "    x_train -= x_mean\n",
    "    x_train /= x_std\n",
    "    x_train[x_train != x_train] = 0\n",
    "\n",
    "    x_test -= x_mean\n",
    "    x_test /= x_std\n",
    "    x_test[x_test != x_test] = 0\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def main():\n",
    "    '''\n",
    "    This is an example of how to use the framework when completed. You can build off of this code to design your experiments for part 2.\n",
    "    '''\n",
    "\n",
    "    x_train, y_train, x_test, y_test = normalize_mnist()\n",
    "\n",
    "    '''\n",
    "    For the experiment, adjust the list [784,...,10] as desired to test other architectures.\n",
    "    You are encouraged to play around with any of the following values if you so desire:\n",
    "    E, lr, bs, activation\n",
    "    '''\n",
    "\n",
    "    model = MLP([784, 256, 10])\n",
    "    model.initialize()\n",
    "    model.set_hp(lr = 1e-6, bs = 512, activation = ReLU)\n",
    "\n",
    "    E = 25\n",
    "    for _ in range(E):\n",
    "        TrainMLP(model, x_train, y_train)\n",
    "        TestMLP(model, x_test, y_test)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
